{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd371431",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b52658",
   "metadata": {},
   "source": [
    "## SDLC Use Case Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c13e910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "from IPython.display import Markdown\n",
    "from langchain_core.messages import HumanMessage\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d51d7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['LANGSMITH_TRACING'] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dfb38a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY environment variable not set.\")\n",
    "client = Groq(api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "abd21eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US001\n",
      "FR-US001-001\n"
     ]
    }
   ],
   "source": [
    "uCounter = itertools.count(1)\n",
    "fCounter = itertools.count(1)\n",
    "us_id = f\"{next(uCounter):03d}\"\n",
    "fr_id = f\"{next(uCounter):03d}\"\n",
    "UserStory_id = f\"US-{us_id}\"\n",
    "FR_id = f\"FR-{us_id}-{fr_id}\"\n",
    "\n",
    "uids = (f\"{i:03d}\" for i in range(1, 100))\n",
    "fids = (f\"{i:03d}\" for i in range(1, 100))\n",
    "uids_next = f\"{next(uids)}\"\n",
    "fids_next = f\"{next(fids)}\"\n",
    "story_id = f\"US{uids_next}\"\n",
    "func_id = f\"FR-{story_id}-{fids_next}\"\n",
    "print(story_id)\n",
    "print(func_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9cc77bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stories_system_prompt = \"\"\"\n",
    "** Role & Objective **\n",
    "\n",
    "You are an expert Agile Product Owner specializing in crafting clear, concise, and actionable User Stories.  \n",
    "Your task is to analyze the provided `user_story` and `user_feedback`, identify gaps or ambiguities, and refine or enhance the User Stories accordingly.  \n",
    "Return the final output strictly in the specified JSON format.\n",
    "\n",
    "---\n",
    "\n",
    "**TASK BREAKDOWN:**\n",
    "\n",
    "1. Carefully analyze the input `user_story` and `user_feedback`.  \n",
    "2. Identify missing information, unclear language, or inconsistencies.  \n",
    "3. Refine the User Stories to ensure they follow the standard format:  \n",
    "   - \"As a [user], I want [goal], so that [value].\"  \n",
    "4. Write **2 to 4** clear, specific, and testable acceptance criteria per story.  \n",
    "5. Maintain alignment with business goals and user needs.  \n",
    "6. Avoid technical implementation details or vague language.  \n",
    "7. Ensure each User Story is independent, coherent, and ready for development.\n",
    "\n",
    "---\n",
    "\n",
    "**EXPECTED OUTPUT FORMAT (JSON array):**\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"story_id\": \"{story_id}\",\n",
    "    \"title\": \"Customer Allocation - Item Substitution Scenario - IteM\",\n",
    "    \"description\": \"Manage the allocation and substitution of items based on availability and allocation rules to ensure correct order quantities.\",\n",
    "    \"acceptance_criteria\": [\n",
    "      {\n",
    "        \"{story_id}-{func_id}\": \"Does original item have substitutes?\",\n",
    "        \"{story_id}-{func_id}\": \"If yes, check sub rank 1 first.\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "**GUIDELINES:**\n",
    "\n",
    "- Ensure each User Story is clear, independent, and testable.\n",
    "- Incorporate user feedback without losing sight of core business objectives.\n",
    "- Acceptance criteria must be between 2 and 4 concise, measurable points.\n",
    "- Avoid technical jargon, implementation details, or vague requirements.\n",
    "- Use consistent and professional language suitable for Agile teams.\n",
    "- Respond only with the JSON output as specified. Do not include explanations or additional text. \n",
    "\n",
    "\n",
    "**Enhancements made:**\n",
    "\n",
    "- Clarified role and task objectives.  \n",
    "- Emphasized standard user story format and acceptance criteria quality.  \n",
    "- Added instructions to avoid technical details and vague language.  \n",
    "- Specified strict output format and response behavior.  \n",
    "- Improved formatting and readability for easier parsing by LLMs.\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "df97ecbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does original item have substitutes?'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_title = \"LeeSar: Your End-to-End Order Management Solution\"\n",
    "project_description = \"LeeSar is a comprehensive Order Management application that allows users to perform seamless transactions using the Fusion Order Management (FOM). Beyond Basic Order, it offers Extensions on the Orders that are created.\"\n",
    "requirements = [\n",
    "    \"Does original item have substitutes?\"\n",
    "]\n",
    "requirements_string = \"\\n\".join(requirements)\n",
    "requirements_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ee28303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "llm = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# parser = JsonOutputParser(pydantic_object=Products)\n",
    "parser = JsonOutputParser()\n",
    "format = parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "346eb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"{system_prompt} \\n {format_instruction} \\n {human_query} \\n\",\n",
    "    input_variables= [\"system_prompt\", \"human_query\",],\n",
    "    partial_variables={\"format_instruction\" : parser.get_format_instructions()}\n",
    ")\n",
    "#prompt.model_dump_json(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ea32fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_story_from_llm(project_title, project_description, user_story_requirements):\n",
    "    user_query = f\"Create User Stories for the Scenario for the \\nProject Title: {project_title}, \\nProject Description: {project_description} and \\nUser Story Requirement: {user_story_requirements}\"\n",
    "    chain = prompt | llm | parser\n",
    "    invoke_input = {\"system_prompt\" : user_stories_system_prompt, \"human_query\" : user_query}\n",
    "    response = chain.invoke(invoke_input)\n",
    "    #Markdown(response)\n",
    "    #print(response)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6744da0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'story_id': 'LS-001',\n",
       "  'title': 'Customer Allocation - Item Substitution Scenario',\n",
       "  'description': 'As a customer service representative, I want to check if an original item has substitutes, so that I can provide the customer with alternatives if the item is out of stock or not available.',\n",
       "  'acceptance_criteria': [{'LS-001-AC1': 'The system displays a list of substitutes for the original item when it is out of stock or not available.',\n",
       "    'LS-001-AC2': 'The substitutes are ranked based on their availability and allocation rules.',\n",
       "    'LS-001-AC3': 'The system alerts the customer service representative if no substitutes are available for the original item.'}]}]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_stories = generate_user_story_from_llm(project_title, project_description, requirements_string)\n",
    "user_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b5faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vagenticai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
